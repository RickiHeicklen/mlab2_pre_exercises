{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat, reduce\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_all_equal(actual: t.Tensor, expected: t.Tensor) -> None:\n",
    "    assert actual.shape == expected.shape, f\"Shape mismatch, got: {actual.shape}\"\n",
    "    assert (actual == expected).all(), f\"Value mismatch, got: {actual}\"\n",
    "    print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_all_close(actual: t.Tensor, expected: t.Tensor, rtol=1e-05, atol=0.0001) -> None:\n",
    "    assert actual.shape == expected.shape, f\"Shape mismatch, got: {actual.shape}\"\n",
    "    assert t.allclose(actual, expected, rtol=rtol, atol=atol)\n",
    "    print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def rearrange_1() -> t.Tensor:\n",
    "    \"\"\"Return the following tensor using only torch.arange and einops.rearrange:\n",
    "\n",
    "    [[3, 4],\n",
    "     [5, 6],\n",
    "     [7, 8]]\n",
    "    \"\"\"\n",
    "    return rearrange(t.arange(3,9), '(row col) -> row col', col= 2)\n",
    "\n",
    "expected = t.tensor([[3, 4], [5, 6], [7, 8]])\n",
    "assert_all_equal(rearrange_1(), expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def rearrange_2() -> t.Tensor:\n",
    "    \"\"\"Return the following tensor using only torch.arange and einops.rearrange:\n",
    "\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6]]\n",
    "    \"\"\"\n",
    "    return rearrange(t.arange(1,7), '(row col) -> row col', col= 3)\n",
    "\n",
    "assert_all_equal(rearrange_2(), t.tensor([[1, 2, 3], [4, 5, 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def rearrange_3() -> t.Tensor:\n",
    "    \"\"\"Return the following tensor using only torch.arange and einops.rearrange:\n",
    "\n",
    "    [[[1], [2], [3], [4], [5], [6]]]\n",
    "    \"\"\"\n",
    "    return rearrange(t.arange(1,7), '(row col1 col2) -> row col1 col2', col1 = 6, col2 = 1)\n",
    "\n",
    "assert_all_equal(rearrange_3(), t.tensor([[[1], [2], [3], [4], [5], [6]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def temperatures_average(temps: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Return the average temperature for each week.\n",
    "\n",
    "    temps: a 1D temperature containing temperatures for each day.\n",
    "    Length will be a multiple of 7 and the first 7 days are for the first week, second 7 days for the second week, etc.\n",
    "\n",
    "    You can do this with a single call to reduce.\n",
    "    \"\"\"\n",
    "    assert len(temps) % 7 == 0\n",
    "    return reduce(temps, '(w1 w2) -> w1', 'mean', w2=7)\n",
    "\n",
    "temps = t.Tensor([71, 72, 70, 75, 71, 72, 70, 68, 65, 60, 68, 60, 55, 59, 75, 80, 85, 80, 78, 72, 83])\n",
    "expected = t.tensor([71.5714, 62.1429, 79.0])\n",
    "assert_all_close(temperatures_average(temps), expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def temperatures_differences(temps: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"For each day, subtract the average for the week the day belongs to.\n",
    "\n",
    "    temps: as above\n",
    "    \"\"\"\n",
    "    assert len(temps) % 7 == 0\n",
    "    \n",
    "    ['collapse comment'\n",
    "        # print(temps)\n",
    "        # print(avg)\n",
    "        # avg2 = reduce(temps, '(w1 w2) -> w1 ()', 'mean', w2=7)\n",
    "        # print(avg2)\n",
    "        # print(avg_repeated)\n",
    "        # print(temps - avg_repeated)\n",
    "        # temps_rearranged = rearrange(temps, '(w1 w2) -> w1 w2', w2 = 7)\n",
    "        # print(temps_rearranged)\n",
    "        # rearrange(temps_rearranged - avg2, 'h w -> (h w)')\n",
    "     ]\n",
    "\n",
    "    avg = temperatures_average(temps)\n",
    "    avg_repeated = repeat(avg, 'h -> (h 7)')\n",
    "\n",
    "    return temps - avg_repeated \n",
    "    \n",
    "expected = t.tensor(\n",
    "    [\n",
    "        -0.5714,\n",
    "        0.4286,\n",
    "        -1.5714,\n",
    "        3.4286,\n",
    "        -0.5714,\n",
    "        0.4286,\n",
    "        -1.5714,\n",
    "        5.8571,\n",
    "        2.8571,\n",
    "        -2.1429,\n",
    "        5.8571,\n",
    "        -2.1429,\n",
    "        -7.1429,\n",
    "        -3.1429,\n",
    "        -4.0,\n",
    "        1.0,\n",
    "        6.0,\n",
    "        1.0,\n",
    "        -1.0,\n",
    "        -7.0,\n",
    "        4.0,\n",
    "    ]\n",
    ")\n",
    "\n",
    "actual = temperatures_differences(temps)\n",
    "assert_all_close(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def temperatures_normalized(temps: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"For each day, subtract the weekly average and divide by the weekly standard deviation.\n",
    "\n",
    "    temps: as above\n",
    "\n",
    "    Pass torch.std to reduce.\n",
    "    \"\"\"\n",
    "\n",
    "    temp_diff = temperatures_differences(temps) \n",
    "    # print(temp_diff)\n",
    "    \n",
    "    temps_diff_rearranged = rearrange(temp_diff, '(w1 w2) -> w1 w2', w2 = 7)\n",
    "    # print(temps_diff_rearranged)\n",
    "\n",
    "    temps_std = reduce(temps_diff_rearranged, 'h w -> h', t.std)\n",
    "    # print(temps_std)\n",
    "    \n",
    "    temps_std_rearranged = rearrange(temps_std, 'w -> w 1')\n",
    "    # print(temps_std_rearranged)\n",
    "    return rearrange(temps_diff_rearranged / temps_std_rearranged, 'h w -> (h w)')\n",
    "\n",
    "expected = t.tensor(\n",
    "    [\n",
    "        -0.3326,\n",
    "        0.2494,\n",
    "        -0.9146,\n",
    "        1.9954,\n",
    "        -0.3326,\n",
    "        0.2494,\n",
    "        -0.9146,\n",
    "        1.1839,\n",
    "        0.5775,\n",
    "        -0.4331,\n",
    "        1.1839,\n",
    "        -0.4331,\n",
    "        -1.4438,\n",
    "        -0.6353,\n",
    "        -0.8944,\n",
    "        0.2236,\n",
    "        1.3416,\n",
    "        0.2236,\n",
    "        -0.2236,\n",
    "        -1.5652,\n",
    "        0.8944,\n",
    "    ]\n",
    ")\n",
    "actual = temperatures_normalized(temps)\n",
    "assert_all_close(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def batched_dot_product_nd(a: t.Tensor, b: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Return the batched dot product of a and b, where the first dimension is the batch dimension.\n",
    "\n",
    "    That is, out[i] = dot(a[i], b[i]) for i in 0..len(a).\n",
    "    a and b can have any number of dimensions greater than 1.\n",
    "\n",
    "    a: shape (b, i_1, i_2, ..., i_n)\n",
    "    b: shape (b, i_1, i_2, ..., i_n)\n",
    "\n",
    "    Returns: shape (b, )\n",
    "\n",
    "    Use torch.einsum. You can use the ellipsis \"...\" in the einsum formula to represent an arbitrary number of dimensions.\n",
    "    \"\"\"\n",
    "    assert a.shape == b.shape\n",
    "    return(t.einsum('i...,i... ->i',[a,b]))\n",
    "\n",
    "actual = batched_dot_product_nd(t.tensor([[1, 1, 0], \n",
    "                                          [0, 0, 1]]), \n",
    "                                t.tensor([[1, 1, 0], \n",
    "                                          [1, 1, 0]]))\n",
    "expected = t.tensor([2, \n",
    "                     0])\n",
    "assert_all_equal(actual, expected)\n",
    "actual2 = batched_dot_product_nd(t.arange(12).reshape((3, 2, 2)), t.arange(12).reshape((3, 2, 2)))\n",
    "expected2 = t.tensor([14, 126, 366])\n",
    "assert_all_equal(actual2, expected2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def identity_matrix(n: int) -> t.Tensor:\n",
    "    \"\"\"Return the identity matrix of size nxn.\n",
    "\n",
    "    Don't use torch.eye or similar.\n",
    "\n",
    "    Hint: you can do it with arange, rearrange, and ==.\n",
    "    Bonus: find a different way to do it.\n",
    "    \"\"\"\n",
    "    assert n >= 0\n",
    "\n",
    "    if n==0:\n",
    "       return t.zeros((0, 0))\n",
    "    x = t.arange(0,n*n)\n",
    "    y = rearrange(x, '(i b) -> i b', b=n)\n",
    "    z = y % (n + 1)\n",
    "    return ((z == 0) * 1)\n",
    "\n",
    "assert_all_equal(identity_matrix(3), t.Tensor([[1, 0, 0], \n",
    "                                               [0, 1, 0], \n",
    "                                               [0, 0, 1]]))\n",
    "assert_all_equal(identity_matrix(0), t.zeros((0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def sample_distribution(probs: t.Tensor, n: int) -> t.Tensor:\n",
    "    \"\"\"Return n random samples from probs, where probs is a normalized probability distribution.\n",
    "\n",
    "    probs: shape (k,) where probs[i] is the probability of event i occurring.\n",
    "    n: number of random samples\n",
    "\n",
    "    Return: shape (n,) where out[i] is an integer indicating which event was sampled.\n",
    "\n",
    "    Use torch.rand and torch.cumsum to do this without any explicit loops.\n",
    "\n",
    "    Note: if you think your solution is correct but the test is failing, try increasing the value of n.\n",
    "    \"\"\"\n",
    "    assert abs(probs.sum() - 1.0) < 0.001\n",
    "    assert (probs >= 0).all()\n",
    "\n",
    "    rn = repeat(t.rand(n), 'i -> i repeat', repeat=len(probs))\n",
    "    m = repeat(t.cumsum(probs, dim=0), 'i -> repeat i', repeat=n)\n",
    "\n",
    "    arr = reduce((rn > m) * 1, 'n probs -> n', 'sum')\n",
    "\n",
    "    return arr\n",
    "\n",
    "n = 10000000\n",
    "probs = t.tensor([0.05, 0.1, 0.1, 0.2, 0.15, 0.4])\n",
    "\n",
    "freqs = t.bincount(sample_distribution(probs, n)) / n\n",
    "\n",
    "assert_all_close(freqs, probs, rtol=0.001, atol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_accuracy(scores: t.Tensor, true_classes: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Return the fraction of inputs for which the maximum score corresponds to the true class for that input.\n",
    "\n",
    "    scores: shape (batch, n_classes). A higher score[b, i] means that the classifier thinks class i is more likely.\n",
    "    true_classes: shape (batch, ). true_classes[b] is an integer from [0...n_classes).\n",
    "\n",
    "    Use torch.argmax.\n",
    "    \"\"\"\n",
    "    assert true_classes.max() < scores.shape[1]\n",
    "\n",
    "    am = t.argmax(scores, dim=1)\n",
    "    pct = ((am == true_classes) * 1).sum() / len(true_classes)\n",
    "    return(pct)\n",
    "\n",
    "scores = t.tensor([[0.75, 0.5, 0.25], [0.1, 0.5, 0.4], [0.1, 0.7, 0.2]])\n",
    "true_classes = t.tensor([0, 1, 0])\n",
    "expected = 2.0 / 3.0\n",
    "assert classifier_accuracy(scores, true_classes) == expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_price_indexing(prices: t.Tensor, items: t.Tensor) -> float:\n",
    "    \"\"\"Given prices for each kind of item and a tensor of items purchased, return the total price.\n",
    "\n",
    "    prices: shape (k, ). prices[i] is the price of the ith item.\n",
    "    items: shape (n, ). A 1D tensor where each value is an item index from [0..k).\n",
    "\n",
    "    Use integer array indexing. The below document describes this for NumPy but it's the same in PyTorch:\n",
    "\n",
    "    https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
    "    \"\"\"\n",
    "    assert items.max() < prices.shape[0] \n",
    "    return prices[(items)].sum()\n",
    "\n",
    "prices = t.tensor([0.5, 1, 1.5, 2, 2.5])\n",
    "items = t.tensor([0, 0, 1, 1, 4, 3, 2])\n",
    "assert total_price_indexing(prices, items) == 9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def gather_2d(matrix: t.Tensor, indexes: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Perform a gather operation along the second dimension.\n",
    "\n",
    "    matrix: shape (m, n)\n",
    "    indexes: shape (m, k)\n",
    "\n",
    "    Return: shape (m, k). out[i][j] = matrix[i][indexes[i][j]]\n",
    "\n",
    "    For this problem, the test already passes and it's your job to write at least three asserts relating the arguments and the output. This is a tricky function and worth spending some time to wrap your head around its behavior.\n",
    "\n",
    "    See: https://pytorch.org/docs/stable/generated/torch.gather.html?highlight=gather#torch.gather\n",
    "    \"\"\"\n",
    "\n",
    "    assert matrix.shape[0] == indexes.shape[0] # equivalent to len(indexes) == len(matrix)\n",
    "    assert len(matrix.shape) == len(indexes.shape)\n",
    "    assert matrix.shape[1] >= indexes.shape[1]\n",
    "    out = matrix.gather(1, indexes)\n",
    "    assert indexes.shape == out.shape\n",
    "    return out\n",
    "\n",
    "\n",
    "matrix = t.arange(15).view(3, 5)\n",
    "indexes = t.tensor([[4], [3], [2]])\n",
    "expected = t.tensor([[4], [8], [12]])\n",
    "assert_all_equal(gather_2d(matrix, indexes), expected)\n",
    "indexes2 = t.tensor([[2, 4], [1, 3], [0, 2]])\n",
    "expected2 = t.tensor([[2, 4], [6, 8], [10, 12]])\n",
    "assert_all_equal(gather_2d(matrix, indexes2), expected2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_price_gather(prices: t.Tensor, items: t.Tensor) -> float:\n",
    "    \"\"\"Compute the same as total_price_indexing, but use torch.gather.\"\"\"\n",
    "    assert items.max() < prices.shape[0]\n",
    "    \n",
    "    return prices.gather(0, items).sum()\n",
    "\n",
    "prices = t.tensor([0.5, 1, 1.5, 2, 2.5])\n",
    "items = t.tensor([0, 0, 1, 1, 4, 3, 2])\n",
    "assert total_price_gather(prices, items) == 9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def integer_array_indexing(matrix: t.Tensor, coords: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Return the values at each coordinate using integer array indexing.\n",
    "\n",
    "    For details on integer array indexing, see:\n",
    "    https://numpy.org/doc/stable/user/basics.indexing.html#integer-array-indexing\n",
    "\n",
    "    matrix: shape (d_0, d_1, ..., d_n)\n",
    "    coords: shape (batch, n)\n",
    "\n",
    "    Return: (batch, )\n",
    "    \"\"\"\n",
    "\n",
    "    rearranged_coords = rearrange(coords, 'i j -> j i')\n",
    "    return matrix[np.array(rearranged_coords)]\n",
    "\n",
    "mat_2d = t.arange(15).view(3, 5)\n",
    "\n",
    "coords_2d = t.tensor([[0, 1], \n",
    "                      [0, 4], \n",
    "                      [1, 4]])\n",
    "actual = integer_array_indexing(mat_2d, coords_2d)\n",
    "assert_all_equal(actual, t.tensor([1, 4, 9]))\n",
    "\n",
    "mat_3d = t.arange(2 * 3 * 4).view((2, 3, 4))\n",
    "coords_3d = t.tensor([[0, 0, 0], \n",
    "                      [0, 1, 1], \n",
    "                      [0, 2, 2], \n",
    "                      [1, 0, 3], \n",
    "                      [1, 2, 0]])\n",
    "actual = integer_array_indexing(mat_3d, coords_3d)\n",
    "assert_all_equal(actual, t.tensor([0, 5, 10, 15, 20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def batched_logsumexp(matrix: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"For each row of the matrix, compute log(sum(exp(row))) in a numerically stable way.\n",
    "\n",
    "    matrix: shape (batch, n)\n",
    "\n",
    "    Return: (batch, ). For each i, out[i] = log(sum(exp(matrix[i]))).\n",
    "\n",
    "    Do this without using PyTorch's logsumexp function.\n",
    "\n",
    "    A couple useful blogs about this function:\n",
    "    - https://leimao.github.io/blog/LogSumExp/\n",
    "    - https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/\n",
    "    \"\"\"\n",
    "    maxxed = reduce(matrix, 'i j -> i ()', 'max')\n",
    "    diffed = matrix - maxxed\n",
    "    exped = np.exp(diffed)\n",
    "    summed = reduce(exped, 'i j -> i ()', 'sum')\n",
    "    logged = np.log(summed)\n",
    "    out = t.flatten(maxxed+logged)\n",
    "    return out\n",
    "\n",
    "\n",
    "matrix = t.tensor([[-1000, -1000, -1000, -1000], [1000, 1000, 1000, 1000]])\n",
    "expected = t.tensor([-1000 + math.log(4), 1000 + math.log(4)])\n",
    "actual = batched_logsumexp(matrix)\n",
    "# assert_all_close(actual, expected)\n",
    "matrix2 = t.randn((10, 20))\n",
    "expected2 = t.logsumexp(matrix2, dim=-1)\n",
    "actual2 = batched_logsumexp(matrix2)\n",
    "assert_all_close(actual2, expected2)\n",
    "\n",
    "# TODO: figure out why log 0 converts the type to float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n",
      "Passed!\n",
      "Passed!\n",
      "Passed!\n",
      "Passed!\n",
      "Passed!\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def batched_softmax(matrix: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"For each row of the matrix, compute softmax(row).\n",
    "\n",
    "    Do this without using PyTorch's softmax function.\n",
    "    Instead, use the definition of softmax: https://en.wikipedia.org/wiki/Softmax_function\n",
    "\n",
    "    matrix: shape (batch, n)\n",
    "\n",
    "    Return: (batch, n). For each i, out[i] should sum to 1.\n",
    "    \"\"\"\n",
    "    i = np.exp(matrix)\n",
    "    s = np.exp(matrix).sum()\n",
    "    out = i / s\n",
    "    return out\n",
    "\n",
    "matrix = t.arange(1, 6).view((1, 5)).float().log()\n",
    "expected = t.arange(1, 6).view((1, 5)) / 15.0\n",
    "actual = batched_softmax(matrix)\n",
    "assert_all_close(actual, expected)\n",
    "\n",
    "assert_all_close(actual, expected)\n",
    "for i in [0.12, 3.4, -5, 6.7]:\n",
    "    assert_all_close(actual, batched_softmax(matrix + i))\n",
    "matrix2 = t.rand((10, 20))\n",
    "actual2 = batched_softmax(matrix2)\n",
    "assert actual2.min() >= 0.0\n",
    "assert actual2.max() <= 1.0\n",
    "assert_all_equal(actual2.argsort(), matrix2.argsort())\n",
    "# assert_all_close(actual2.sum(dim=-1), t.ones(matrix2.shape[:-1]))\n",
    "\n",
    "# TODO: figure out why the last one is an array of 0.1 and then an array of 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This whole problem\n",
    "\n",
    "def batched_logsoftmax(matrix: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Compute log(softmax(row)) for each row of the matrix.\n",
    "\n",
    "    matrix: shape (batch, n)\n",
    "\n",
    "    Return: (batch, n). For each i, out[i] should sum to 1.\n",
    "\n",
    "    Do this without using PyTorch's logsoftmax function.\n",
    "    For each row, subtract the maximum first to avoid overflow if the row contains large values.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "matrix = t.arange(1, 6).view((1, 5)).float()\n",
    "start = 1000\n",
    "matrix2 = t.arange(start + 1, start + 6).view((1, 5)).float()\n",
    "actual = batched_logsoftmax(matrix2)\n",
    "expected = t.tensor([[-4.4519, -3.4519, -2.4519, -1.4519, -0.4519]])\n",
    "assert_all_close(actual, expected)\n",
    "\n",
    "# print(matrix)\n",
    "# print(matrix2)\n",
    "# print(actual)\n",
    "# print(expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This whole problem\n",
    "\n",
    "def batched_cross_entropy_loss(logits: t.Tensor, true_labels: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Compute the cross entropy loss for each example in the batch.\n",
    "\n",
    "    logits: shape (batch, classes). logits[i][j] is the unnormalized prediction for example i and class j.\n",
    "    true_labels: shape (batch, ). true_labels[i] is an integer index representing the true class for example i.\n",
    "\n",
    "    Return: shape (batch, ). out[i] is the loss for example i.\n",
    "\n",
    "    Hint: convert the logits to log-probabilities using your batched_logsoftmax from above.\n",
    "    Then the loss for an example is just the negative of the log-probability that the model assigned to the true class. Use torch.gather to perform the indexing.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "logits = t.tensor([[float(\"-inf\"), float(\"-inf\"), 0], [1 / 3, 1 / 3, 1 / 3], [float(\"-inf\"), 0, 0]])\n",
    "true_labels = t.tensor([2, 0, 0])\n",
    "expected = t.tensor([0.0, math.log(3), float(\"inf\")])\n",
    "actual = batched_cross_entropy_loss(logits, true_labels)\n",
    "assert_all_close(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def collect_rows(matrix: t.Tensor, row_indexes: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Return a 2D matrix whose rows are taken from the input matrix in order according to row_indexes.\n",
    "\n",
    "    matrix: shape (m, n)\n",
    "    row_indexes: shape (k,). Each value is an integer in [0..m).\n",
    "\n",
    "    Return: shape (k, n). out[i] is matrix[row_indexes[i]].\n",
    "    \"\"\"\n",
    "    assert row_indexes.max() < matrix.shape[0]\n",
    "\n",
    "    return matrix[row_indexes]\n",
    "\n",
    "matrix = t.arange(15).view((5, 3))\n",
    "row_indexes = t.tensor([0, 2, 1, 0])\n",
    "actual = collect_rows(matrix, row_indexes)\n",
    "expected = t.tensor([[0, 1, 2], \n",
    "                     [6, 7, 8], \n",
    "                     [3, 4, 5], \n",
    "                     [0, 1, 2]])\n",
    "assert_all_equal(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def collect_columns(matrix: t.Tensor, column_indexes: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Return a 2D matrix whose columns are taken from the input matrix in order according to column_indexes.\n",
    "\n",
    "    matrix: shape (m, n)\n",
    "    column_indexes: shape (k,). Each value is an integer in [0..n).\n",
    "\n",
    "    Return: shape (m, k). out[:, i] is matrix[:, column_indexes[i]].\n",
    "    \"\"\"\n",
    "    assert column_indexes.max() < matrix.shape[1]\n",
    "    t = rearrange(matrix, 'i j -> j i')\n",
    "    r = collect_rows(t, column_indexes)\n",
    "    rt = rearrange(r, 'i j -> j i')\n",
    "    return rt\n",
    "\n",
    "\n",
    "matrix = t.arange(15).view((5, 3))\n",
    "column_indexes = t.tensor([0, 2, 1, 0])\n",
    "actual = collect_columns(matrix, column_indexes)\n",
    "expected = t.tensor([[0, 2, 1, 0], \n",
    "                     [3, 5, 4, 3], \n",
    "                     [6, 8, 7, 6], \n",
    "                     [9, 11, 10, 9], \n",
    "                     [12, 14, 13, 12]])\n",
    "assert_all_equal(actual, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice with `torch.as_strided`\n",
    "\n",
    "If you're not familiar with `as_strided`, a couple good resources are:\n",
    "\n",
    "- [NumPy For Your Grandma (4 minute video)](https://www.youtube.com/watch?v=VlkzN00P0Bc)\n",
    "- [as_strided and sum are all you need](https://jott.live/markdown/as_strided)\n",
    "\n",
    "Fill in the \"size\" and \"stride\" arguments so that a call to `as_strided` produces the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0 passed!\n",
      "Test 1 passed!\n",
      "Test 2 passed!\n",
      "Test 3 passed!\n",
      "Test 4 passed!\n",
      "Test 5 passed!\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "TestCase = namedtuple(\"TestCase\", [\"output\", \"size\", \"stride\"])\n",
    "test_input_a = t.tensor([[0, 1, 2, 3, 4], \n",
    "                         [5, 6, 7, 8, 9], \n",
    "                         [10, 11, 12, 13, 14], \n",
    "                         [15, 16, 17, 18, 19]])\n",
    "test_cases = [\n",
    "    TestCase(output=t.tensor([0, 1, 2, 3]), size=(1,4), stride=(1,1)),\n",
    "    TestCase(output=t.tensor([[0, 1, 2], [5, 6, 7]]), size=(2,3), stride=(5,1)),\n",
    "    TestCase(output=t.tensor([[0, 0, 0], [11, 11, 11]]), size=(2,3), stride=(11,0)),\n",
    "    TestCase(output=t.tensor([0, 6, 12, 18]), size=(1,4), stride=(1,6)),\n",
    "    TestCase(output=t.tensor([[[0, 1, 2]], [[9, 10, 11]]]), size=(2,1,3), stride=(9,0,1)),\n",
    "    TestCase(\n",
    "        output=t.tensor([[[[0, 1], [2, 3]], [[4, 5], [6, 7]]], [[[12, 13], [14, 15]], [[16, 17], [18, 19]]]]),\n",
    "        size=(2,2,2,2),\n",
    "        stride=(12,4,2,1),\n",
    "    ),\n",
    "]\n",
    "for (i, case) in enumerate(test_cases):\n",
    "    # print(i)\n",
    "    # print(case)\n",
    "    actual = test_input_a.as_strided(size=case.size, stride=case.stride)\n",
    "    if (case.output != actual).any():\n",
    "        print(f\"Test {i} failed:\")\n",
    "        print(f\"Expected: {case.output}\")\n",
    "        print(f\"Actual: {actual}\")\n",
    "    else:\n",
    "        print(f\"Test {i} passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Implementing ReLU\n",
    "\n",
    "Implement ReLU five different ways.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_relu(relu_func):\n",
    "    print(f\"Testing: {relu_func.__name__}\")\n",
    "    x = t.arange(-1, 3, dtype=t.float32, requires_grad=True)\n",
    "    out = relu_func(x)\n",
    "    expected = t.tensor([0.0, 0.0, 1.0, 2.0])\n",
    "    assert_all_close(out, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: relu_clone_setitem\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def relu_clone_setitem(x: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Make a copy with torch.clone and then assign to parts of the copy.\"\"\"\n",
    "    y = t.clone(x)\n",
    "    y_relu = t.tensor([i if i > 0 else 0 for i in y])\n",
    "    return y_relu\n",
    "\n",
    "test_relu(relu_clone_setitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: relu_where\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def relu_where(x: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Use torch.where.\"\"\"\n",
    "    return (t.where(x > 0, x, 0))\n",
    "    \n",
    "test_relu(relu_where)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: relu_maximum\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def relu_maximum(x: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Use torch.maximum.\"\"\"\n",
    "    return t.maximum(x, t.tensor([0 for i in x]))\n",
    "\n",
    "test_relu(relu_maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: relu_abs\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def relu_abs(x: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Use torch.abs.\"\"\"\n",
    "    return (t.abs(x) + x) / 2\n",
    "\n",
    "test_relu(relu_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: relu_multiply_bool\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "def relu_multiply_bool(x: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"Create a boolean tensor and multiply the input by it elementwise.\"\"\"\n",
    "    y = x >= 0\n",
    "    return x * y\n",
    "\n",
    "test_relu(relu_multiply_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
